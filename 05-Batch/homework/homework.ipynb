{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0578c8aa-eb50-460c-a8ff-2f6c9f8643c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3.2\n",
      "/home/de-camptliu/spark/spark-3.3.2-bin-hadoop3/python/pyspark/__init__.py\n"
     ]
    }
   ],
   "source": [
    " import pyspark\n",
    " print(pyspark.__version__)\n",
    " print(pyspark.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5b221fc-3c59-4acc-ad92-6d5fd487fb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-01 00:06:35--  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-10.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 18.161.140.201, 18.161.140.124, 18.161.140.125, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|18.161.140.201|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 64346071 (61M) [binary/octet-stream]\n",
      "Saving to: ‘yellow_tripdata_2024-10.parquet’\n",
      "\n",
      "yellow_tripdata_202 100%[===================>]  61.36M   161MB/s    in 0.4s    \n",
      "\n",
      "2025-03-01 00:06:35 (161 MB/s) - ‘yellow_tripdata_2024-10.parquet’ saved [64346071/64346071]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-10.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba8350e4-da72-4746-a90f-936ccdb5eef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/03/01 00:08:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/03/01 00:08:29 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "# Create a local spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78ceef97-9cd8-4e10-b2eb-d8642f9d54f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       2| 2024-10-01 00:30:44|  2024-10-01 00:48:26|              1|          3.0|         1|                 N|         162|         246|           1|       18.4|  1.0|    0.5|       1.5|         0.0|                  1.0|        24.9|                 2.5|        0.0|\n",
      "|       1| 2024-10-01 00:12:20|  2024-10-01 00:25:25|              1|          2.2|         1|                 N|          48|         236|           1|       14.2|  3.5|    0.5|       3.8|         0.0|                  1.0|        23.0|                 2.5|        0.0|\n",
      "|       1| 2024-10-01 00:04:46|  2024-10-01 00:13:52|              1|          2.7|         1|                 N|         142|          24|           1|       13.5|  3.5|    0.5|       3.7|         0.0|                  1.0|        22.2|                 2.5|        0.0|\n",
      "|       1| 2024-10-01 00:12:10|  2024-10-01 00:23:01|              1|          3.1|         1|                 N|         233|          75|           1|       14.2|  3.5|    0.5|       2.0|         0.0|                  1.0|        21.2|                 2.5|        0.0|\n",
      "|       1| 2024-10-01 00:30:22|  2024-10-01 00:30:39|              1|          0.0|         1|                 N|         262|         262|           3|        3.0|  3.5|    0.5|       0.0|         0.0|                  1.0|         8.0|                 2.5|        0.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .parquet('yellow_tripdata_2024-10.parquet')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f293b31-5964-4df4-947b-87ed593946e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3833771"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9bd72be-10c9-42c6-b67f-a3f73f4b856c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 62M\n",
      "drwxr-xr-x 2 de-camptliu de-camptliu 4.0K Mar  1 00:52 df_repart\n",
      "drwxr-xr-x 2 de-camptliu de-camptliu 4.0K Mar  1 00:15 df_repartitioned\n",
      "drwxr-xr-x 2 de-camptliu de-camptliu 4.0K Mar  1 00:48 df_repartitioned1\n",
      "-rw-rw-r-- 1 de-camptliu de-camptliu  14K Mar  1 00:51 homework.ipynb\n",
      "-rw-rw-r-- 1 de-camptliu de-camptliu  13K Feb 22  2024 taxi_zone_lookup.csv\n",
      "-rw-rw-r-- 1 de-camptliu de-camptliu 7.1K Feb 28 23:39 test.ipynb\n",
      "-rw-rw-r-- 1 de-camptliu de-camptliu    9 Feb 28 21:41 test.py\n",
      "-rw-rw-r-- 1 de-camptliu de-camptliu  62M Dec 18 21:21 yellow_tripdata_2024-10.parquet\n",
      "drwxr-xr-x 2 de-camptliu de-camptliu 4.0K Feb 28 23:23 zones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_repartitioned.write.parquet('df_repart') \n",
    "!ls -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03d85246-4551-4477-a988-63e7d5982d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SUCCESS\n",
      "part-00000-6a462667-40bb-4358-a8f7-fa54a02a5479-c000.snappy.parquet\n",
      "part-00001-6a462667-40bb-4358-a8f7-fa54a02a5479-c000.snappy.parquet\n",
      "part-00002-6a462667-40bb-4358-a8f7-fa54a02a5479-c000.snappy.parquet\n",
      "part-00003-6a462667-40bb-4358-a8f7-fa54a02a5479-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls df_repart/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06ace504-2d3d-49b7-876e-507ed535293e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 97M\n",
      "-rw-r--r-- 1 de-camptliu de-camptliu   0 Mar  1 00:52 _SUCCESS\n",
      "-rw-r--r-- 1 de-camptliu de-camptliu 25M Mar  1 00:52 part-00000-6a462667-40bb-4358-a8f7-fa54a02a5479-c000.snappy.parquet\n",
      "-rw-r--r-- 1 de-camptliu de-camptliu 25M Mar  1 00:52 part-00001-6a462667-40bb-4358-a8f7-fa54a02a5479-c000.snappy.parquet\n",
      "-rw-r--r-- 1 de-camptliu de-camptliu 25M Mar  1 00:52 part-00002-6a462667-40bb-4358-a8f7-fa54a02a5479-c000.snappy.parquet\n",
      "-rw-r--r-- 1 de-camptliu de-camptliu 25M Mar  1 00:52 part-00003-6a462667-40bb-4358-a8f7-fa54a02a5479-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -lh df_repart/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6eb0724e-e4a2-4eed-ba1a-ac05b7135025",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 79M\n",
      "-rw-r--r-- 1 de-camptliu de-camptliu   0 Mar  1 00:52 _SUCCESS\n",
      "-rw-r--r-- 1 de-camptliu de-camptliu 22M Mar  1 00:52 part-00000-a410ed7c-9e92-4411-838b-e0b84d42d8a3-c000.snappy.parquet\n",
      "-rw-r--r-- 1 de-camptliu de-camptliu 22M Mar  1 00:52 part-00001-a410ed7c-9e92-4411-838b-e0b84d42d8a3-c000.snappy.parquet\n",
      "-rw-r--r-- 1 de-camptliu de-camptliu 22M Mar  1 00:52 part-00002-a410ed7c-9e92-4411-838b-e0b84d42d8a3-c000.snappy.parquet\n",
      "-rw-r--r-- 1 de-camptliu de-camptliu 14M Mar  1 00:52 part-00003-a410ed7c-9e92-4411-838b-e0b84d42d8a3-c000.snappy.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet('df') \n",
    "!ls -lh df/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "da9cdadd-c3ae-4ad4-b876-3bb650dca3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_date, unix_timestamp, broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54b82954-c2b0-4a23-a376-8b3256a3011c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of taxi trips on October 15th: 128893\n"
     ]
    }
   ],
   "source": [
    "#Q3:\n",
    "# Convert timestamp to date and filter for October 15th\n",
    "df_filtered = df_repartitioned.withColumn(\"pickup_datetime\", to_date(col(\"tpep_pickup_datetime\"))) \\\n",
    "                .filter(col(\"pickup_datetime\") == \"2024-10-15\")\n",
    "\n",
    "# Count the trips\n",
    "trip_count = df_filtered.count()\n",
    "\n",
    "print(f\"Number of taxi trips on October 15th: {trip_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "940cd9fb-db34-4625-b564-3adda54ecf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|trip_count|\n",
      "+----------+\n",
      "|    128893|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using Spark SQL\n",
    "df_repartitioned.createOrReplaceTempView(\"taxi_trips\")\n",
    "\n",
    "result = spark.sql(\"\"\"\n",
    "    SELECT COUNT(*) AS trip_count \n",
    "    FROM taxi_trips \n",
    "    WHERE (tpep_pickup_datetime>= '2024-10-15') AND (tpep_pickup_datetime < '2024-10-16')\n",
    "    --- WHERE DATE(pickup_datetime) = '2024-10-15'\n",
    "\"\"\")\n",
    "\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "663093bb-188a-48df-add4-d3af43f4689e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest trip duration: 162.62 hours\n"
     ]
    }
   ],
   "source": [
    "#Q4\n",
    "# Calculate trip duration in hours\n",
    "df_with_duration = df.withColumn(\"trip_duration_hours\",\n",
    "    (unix_timestamp(col(\"tpep_dropoff_datetime\")) - unix_timestamp(col(\"tpep_pickup_datetime\"))) / 3600\n",
    ")\n",
    "\n",
    "# Find the maximum trip duration\n",
    "max_duration = df_with_duration.selectExpr(\"MAX(trip_duration_hours) AS longest_trip_hours\").collect()[0][0]\n",
    "\n",
    "print(f\"Longest trip duration: {max_duration:.2f} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9b117e4-81ef-42cf-a681-8e70f1727562",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 83:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|longest_trip_hours|\n",
      "+------------------+\n",
      "|162.61777777777777|\n",
      "+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#\n",
    "result = spark.sql(\"\"\"\n",
    "    SELECT MAX((UNIX_TIMESTAMP(tpep_dropoff_datetime) - UNIX_TIMESTAMP(tpep_pickup_datetime)) / 3600) AS longest_trip_hours\n",
    "    FROM taxi_trips\n",
    "\"\"\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ab72657-2fbf-4e3b-b5bb-acaae1ba026f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-01 01:30:36--  https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 18.161.140.125, 18.161.140.41, 18.161.140.201, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|18.161.140.125|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12331 (12K) [text/csv]\n",
      "Saving to: ‘taxi_zone_lookup.csv.1’\n",
      "\n",
      "taxi_zone_lookup.cs 100%[===================>]  12.04K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-03-01 01:30:36 (161 MB/s) - ‘taxi_zone_lookup.csv.1’ saved [12331/12331]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q6\n",
    "!wget https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "21796e53-dfe8-443d-9e36-97acb26c09f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"LocationID\",\"Borough\",\"Zone\",\"service_zone\"\n",
      "1,\"EWR\",\"Newark Airport\",\"EWR\"\n",
      "2,\"Queens\",\"Jamaica Bay\",\"Boro Zone\"\n",
      "3,\"Bronx\",\"Allerton/Pelham Gardens\",\"Boro Zone\"\n",
      "4,\"Manhattan\",\"Alphabet City\",\"Yellow Zone\"\n",
      "5,\"Staten Island\",\"Arden Heights\",\"Boro Zone\"\n",
      "6,\"Staten Island\",\"Arrochar/Fort Wadsworth\",\"Boro Zone\"\n",
      "7,\"Queens\",\"Astoria\",\"Boro Zone\"\n",
      "8,\"Queens\",\"Astoria Park\",\"Boro Zone\"\n",
      "9,\"Queens\",\"Auburndale\",\"Boro Zone\"\n"
     ]
    }
   ],
   "source": [
    "!head taxi_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c962851d-38ee-4e21-944f-126bf45962b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zone = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('taxi_zone_lookup.csv')\n",
    "df_zone.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a32366b8-09ba-47b8-a03b-5c2b83bd83e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 111:==============>                                          (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+----------+---------+--------------------+------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|LocationID|  Borough|                Zone|service_zone|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+----------+---------+--------------------+------------+\n",
      "|       1| 2024-10-07 16:40:43|  2024-10-07 18:10:56|              1|         14.8|        99|                 N|         127|         225|           1|       47.5|  0.0|    0.5|       0.0|        6.94|                  0.0|       54.94|                 0.0|        0.0|       127|Manhattan|              Inwood|   Boro Zone|\n",
      "|       2| 2024-10-04 14:17:41|  2024-10-04 14:26:47|              1|          1.1|         1|                 N|         113|         211|           1|        9.3|  0.0|    0.5|      2.66|         0.0|                  1.0|       15.96|                 2.5|        0.0|       113|Manhattan|Greenwich Village...| Yellow Zone|\n",
      "|       2| 2024-10-01 11:17:28|  2024-10-01 11:32:18|              1|         4.63|         1|                 N|         231|         170|           1|       21.9|  0.0|    0.5|      5.18|         0.0|                  1.0|       31.08|                 2.5|        0.0|       231|Manhattan|TriBeCa/Civic Center| Yellow Zone|\n",
      "|       1| 2024-10-08 17:12:07|  2024-10-08 17:35:56|              1|          2.4|         1|                 N|         236|         100|           1|       19.8|  5.0|    0.5|      5.25|         0.0|                  1.0|       31.55|                 2.5|        0.0|       236|Manhattan|Upper East Side N...| Yellow Zone|\n",
      "|       1| 2024-10-01 15:37:08|  2024-10-01 15:54:23|              1|          2.1|         1|                 N|         237|          75|           1|       16.3|  2.5|    0.5|      4.05|         0.0|                  1.0|       24.35|                 2.5|        0.0|       237|Manhattan|Upper East Side S...| Yellow Zone|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+----------+---------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_joined = df_repartitioned.join(broadcast(df_zone), df_repartitioned[\"PULocationID\"] == df_zone[\"LocationID\"], \"inner\")\n",
    "df_joined.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d9ec68e4-d4f6-4342-b8a2-9e083f60535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined.createOrReplaceTempView(\"joined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "08ec653d-f7d6-4214-9fdf-0e137a4b37ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 125:==============>                                          (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n",
      "|                Zone|num|\n",
      "+--------------------+---+\n",
      "|Governor's Island...|  1|\n",
      "+--------------------+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result = spark.sql('''\n",
    "    SELECT Zone, sum(1) AS num \n",
    "    FROM joined\n",
    "    GROUP BY Zone\n",
    "    ORDER BY num\n",
    "    LIMIT 1\n",
    "''')\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d841689a-a507-4954-a332-c43d1d4d2397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 132:==============>                                          (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n",
      "|                Zone|num|\n",
      "+--------------------+---+\n",
      "|Governor's Island...|  1|\n",
      "+--------------------+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Using function\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Assuming 'joined' is your DataFrame\n",
    "result_df = df_joined.groupBy(\"Zone\") \\\n",
    "                  .agg(F.count(F.lit(1)).alias(\"num\")) \\\n",
    "                  .orderBy(\"num\") \\\n",
    "                  .limit(1)\n",
    "\n",
    "# Show the result\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d185e878-27e5-4f25-8a1f-49c2a4c34094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
